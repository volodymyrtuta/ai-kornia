{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "input = torch.tensor([\n",
    "    [[\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "    ]],\n",
    "    [[\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "    ]],\n",
    "]) \n",
    "print (input.shape)\n",
    "coord, resp = kornia.ConvSoftArgmax2d((3,3), (2,2), padding=(0,0),\n",
    "                                      normalized_coordinates=False,\n",
    "                                      temperature=torch.tensor(10.),\n",
    "                                      output_value=True)(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = input.view(2,1,1,5,5)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from kornia.geometry import dsnt\n",
    "from kornia.utils import create_meshgrid\n",
    "from kornia.geometry import normalize_pixel_coordinates\n",
    "from typing import Tuple, Union\n",
    "def _get_center_kernel3d(d:int, h: int, w: int) -> torch.Tensor:\n",
    "    '''Helper function, which generates a kernel to\n",
    "    return center coordinates, when applied with F.conv2d to 3d coordinates grid\n",
    "    Args:\n",
    "         d (int): kernel depth\n",
    "         h (int): kernel height\n",
    "         w (int): kernel width\n",
    "    Returns:\n",
    "        conv_kernel (torch.Tensor) [3x3xdxhxw]\n",
    "    '''\n",
    "    center_kernel = torch.zeros(3, 3, d, h, w)\n",
    "    center_kernel[0, 0, d // 2, h // 2, w // 2] = 1.0\n",
    "    center_kernel[1, 1, d // 2, h // 2, w // 2] = 1.0\n",
    "    center_kernel[2, 2, d // 2, h // 2, w // 2] = 1.0\n",
    "    return center_kernel\n",
    "\n",
    "def _get_window_grid_kernel3d(d:int, h: int, w: int) -> torch.Tensor:\n",
    "    '''Helper function, which generates a kernel to return coordinates,\n",
    "    residual to window center\n",
    "    Args:\n",
    "         d (int): kernel depth\n",
    "         h (int): kernel height\n",
    "         w (int): kernel width\n",
    "    Returns:\n",
    "        conv_kernel (torch.Tensor) [3x1xdxhxw]\n",
    "    '''\n",
    "    grid2d = create_meshgrid(h, w, True)\n",
    "    z = torch.linspace(-1, 1, d).view(d,1,1,1)\n",
    "    grid3d = torch.cat([z.repeat(1, h, w, 1).contiguous(), grid2d.repeat(d, 1, 1, 1)], dim=3)\n",
    "    conv_kernel = grid3d.permute(3, 0, 1, 2).unsqueeze(1)\n",
    "    return conv_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 1, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "wg = _get_center_kernel3d(4,5,6)\n",
    "print (wg[2,0])\n",
    "print (wg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 13, 25, 3])\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "def create_meshgrid3d(\n",
    "        depth: int,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        normalized_coordinates: Optional[bool] = True) -> torch.Tensor:\n",
    "    \"\"\"Generates a coordinate grid for an image.\n",
    "\n",
    "    When the flag `normalized_coordinates` is set to True, the grid is\n",
    "    normalized to be in the range [-1,1] to be consistent with the pytorch\n",
    "    function grid_sample.\n",
    "    http://pytorch.org/docs/master/nn.html#torch.nn.functional.grid_sample\n",
    "\n",
    "    Args:\n",
    "        depth (int): the image depth (channels).\n",
    "        height (int): the image height (rows).\n",
    "        width (int): the image width (cols).\n",
    "        normalized_coordinates (Optional[bool]): wether to normalize\n",
    "          coordinates in the range [-1, 1] in order to be consistent with the\n",
    "          PyTorch function grid_sample.\n",
    "\n",
    "    Return:\n",
    "        torch.Tensor: returns a grid tensor with shape :math:`(1, D, H, W, 3)`.\n",
    "    \"\"\"\n",
    "    grid2d = create_meshgrid(height, width, normalized_coordinates)\n",
    "    if normalized_coordinates:\n",
    "        z = torch.linspace(-1, 1, depth)\n",
    "    else:\n",
    "        z = torch.linspace(0, depth - 1, depth)\n",
    "    z = z.view (depth, 1, 1, 1)\n",
    "    grid3d = torch.cat([z.repeat(1, height, width, 1).contiguous(), grid2d.repeat(depth, 1, 1, 1)], dim=3)\n",
    "    return grid3d.unsqueeze(0) # 1xDxHxWx3\n",
    "mg3 = create_meshgrid3d(5,13,25)\n",
    "print (mg3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixel_coordinates3d(\n",
    "        pixel_coordinates: torch.Tensor,\n",
    "        depth: int,\n",
    "        height: int,\n",
    "        width: int) -> torch.Tensor:\n",
    "    r\"\"\"Normalize pixel coordinates between -1 and 1.\n",
    "\n",
    "    Normalized, -1 if on extreme left, 1 if on extreme right (x = w-1).\n",
    "\n",
    "    Args:\n",
    "        pixel_coordinate (torch.Tensor): the grid with pixel coordinates.\n",
    "          Shape can be :math:`(*, 3)`.\n",
    "        depth (int): the maximum depth in the z-axis.\n",
    "        height (int): the maximum height in the y-axis.\n",
    "        width (int): the maximum width in the x-axis.\n",
    "\n",
    "    Return:\n",
    "        torch.Tensor: the normalized pixel coordinates.\n",
    "    \"\"\"\n",
    "    if pixel_coordinates.shape[-1] != 3:\n",
    "        raise ValueError(\"Input pixel_coordinates must be of shape (*, 3). \"\n",
    "                         \"Got {}\".format(pixel_coordinates.shape))\n",
    "    # compute normalization factor\n",
    "    dhw: torch.Tensor = torch.stack([\n",
    "        torch.tensor(depth), torch.tensor(width), torch.tensor(height)\n",
    "    ]).to(pixel_coordinates.device).to(pixel_coordinates.dtype)\n",
    "\n",
    "    factor: torch.Tensor = torch.tensor(2.) / (dhw - 1)\n",
    "\n",
    "    return factor * pixel_coordinates - 1\n",
    "\n",
    "\n",
    "def denormalize_pixel_coordinates3d(\n",
    "        pixel_coordinates: torch.Tensor,\n",
    "        depth: int,\n",
    "        height: int,\n",
    "        width: int) -> torch.Tensor:\n",
    "    r\"\"\"Denormalize pixel coordinates.\n",
    "\n",
    "    The input is assumed to be -1 if on extreme left, 1 if on\n",
    "    extreme right (x = w-1).\n",
    "\n",
    "    Args:\n",
    "        pixel_coordinate (torch.Tensor): the normalized grid coordinates.\n",
    "          Shape can be :math:`(*, 3)`.\n",
    "        depth (int): the maximum depth in the x-axis.\n",
    "        height (int): the maximum height in the y-axis.\n",
    "        width (int): the maximum width in the x-axis.\n",
    "\n",
    "    Return:\n",
    "        torch.Tensor: the denormalized pixel coordinates.\n",
    "    \"\"\"\n",
    "    if pixel_coordinates.shape[-1] != 3:\n",
    "        raise ValueError(\"Input pixel_coordinates must be of shape (*, 3). \"\n",
    "                         \"Got {}\".format(pixel_coordinates.shape))\n",
    "    # compute normalization factor\n",
    "    dhw: torch.Tensor = torch.stack([\n",
    "        torch.tensor(depth), torch.tensor(width), torch.tensor(height)\n",
    "    ]).to(pixel_coordinates.device).to(pixel_coordinates.dtype)\n",
    "\n",
    "    factor: torch.Tensor = torch.tensor(2.) / (dhw - 1)\n",
    "\n",
    "    return torch.tensor(1.) / factor * (pixel_coordinates + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 13, 25]) torch.Size([3, 3, 3, 5, 5])\n",
      "torch.Size([1, 3, 5, 13, 25])\n"
     ]
    }
   ],
   "source": [
    "center_kernel = _get_center_kernel3d(3, 5, 5)\n",
    "grid_global = create_meshgrid3d(5, 13, 25, False).permute(0, 4, 1, 2, 3)\n",
    "print (grid_global.shape, center_kernel.shape)\n",
    "grid_global_pooled = F.conv3d(grid_global,\n",
    "                              center_kernel,\n",
    "                              stride=1,\n",
    "                              padding=(1,2,2))\n",
    "print (grid_global_pooled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_soft_argmax3d(input: torch.Tensor,\n",
    "                       kernel_size: Tuple[int, int, int] = (3, 3, 3),\n",
    "                       stride: Tuple[int, int, int] = (1, 1, 1),\n",
    "                       padding: Tuple[int, int, int] = (1, 1, 1),\n",
    "                       temperature: Union[torch.Tensor, float] = torch.tensor(1.0),\n",
    "                       normalized_coordinates: bool = True,\n",
    "                       eps: float = 1e-8,\n",
    "                       output_value: bool = False) -> Union[torch.Tensor,\n",
    "                                                            Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Function that computes the convolutional spatial Soft-Argmax 3D over the windows\n",
    "    of a given input heatmap. Function has two outputs: argmax coordinates and the softmaxpooled heatmap values\n",
    "    themselves.\n",
    "\n",
    "    On each window, the function computed is:\n",
    "\n",
    "    .. math::\n",
    "        ijk(X) = \\frac{\\sum_{(i,j,k) * exp(x / T)  \\in X}} {\\sum_{exp(x / T)  \\in X}}\n",
    "        val(X) = \\frac{\\sum_{x * exp(x / T)  \\in X}} {\\sum_{exp(x / T)  \\in X}}\n",
    "\n",
    "    - where T is temperature.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (Tuple([int,int,int])): the size of the window\n",
    "        stride  (Tuple([int,int,int])): the stride of the window.\n",
    "        padding (Tuple([int,int,int])): input zero padding\n",
    "        temperature (torch.Tensor): factor to apply to input. Default is 1.\n",
    "        normalized_coordinates (bool): whether to return the\n",
    "          coordinates normalized in the range of [-1, 1]. Otherwise,\n",
    "          it will return the coordinates in the range of the input shape.\n",
    "          Default is True.\n",
    "        eps (float): small value to avoid zero division. Default is 1e-8.\n",
    "        output_value(bool): if True, val is outputed, if False, only ij\n",
    "\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`\n",
    "        - Output: math:`(N, C, 3, D_{out}, H_{out}, W_{out})`, :math:`(N, C, D_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{D_{in}  + 2 \\times \\text{padding}[0] -\n",
    "              (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[1] -\n",
    "              (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[2] -\n",
    "              (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> input = torch.randn(20, 16, 3, 50, 32)\n",
    "        >>> nms_coords, nms_val = conv_soft_argmax2d(input, (3, 3, 3), (1, 2, 2), (0, 1, 1))\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(input):\n",
    "        raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                        .format(type(input)))\n",
    "    if not len(input.shape) == 5:\n",
    "        raise ValueError(\"Invalid input shape, we expect BxCxDxHxW. Got: {}\"\n",
    "                         .format(input.shape))\n",
    "    if temperature <= 0:\n",
    "        raise ValueError(\"Temperature should be positive float or tensor. Got: {}\"\n",
    "                         .format(temperature))\n",
    "\n",
    "    b, c, d, h, w = input.shape\n",
    "    input = input.view(b * c, 1, d, h, w)\n",
    "\n",
    "    center_kernel = _get_center_kernel3d(kernel_size[0], kernel_size[1], kernel_size[2])\n",
    "    window_kernel = _get_window_grid_kernel3d(kernel_size[0], kernel_size[1], kernel_size[2])\n",
    "    window_kernel = window_kernel.to(input.device).to(input.dtype)\n",
    "\n",
    "    x_exp = (input / temperature).exp()\n",
    "\n",
    "    pool_coef: float = float(kernel_size[0] * kernel_size[1] * kernel_size[2])\n",
    "\n",
    "    # softmax denominator\n",
    "    den = pool_coef * F.avg_pool3d(x_exp.view(input.size()),\n",
    "                                   kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding) + 1e-12\n",
    "\n",
    "    x_softmaxpool = pool_coef * F.avg_pool3d(x_exp.view(input.size()) * input,\n",
    "                                             kernel_size,\n",
    "                                             stride=stride,\n",
    "                                             padding=padding) / den\n",
    "    x_softmaxpool = x_softmaxpool.view(b,\n",
    "                                       c,\n",
    "                                       x_softmaxpool.size(2),\n",
    "                                       x_softmaxpool.size(3),\n",
    "                                       x_softmaxpool.size(4))\n",
    "\n",
    "    # We need to output also coordinates\n",
    "    # Pooled window center coordinates\n",
    "    grid_global: torch.Tensor = create_meshgrid3d(d, h, w, False).permute(0, 4, 1, 2, 3)\n",
    "    grid_global = grid_global.to(input.device).to(input.dtype)\n",
    "    grid_global_pooled = F.conv3d(grid_global,\n",
    "                                  center_kernel.to(input.device).to(input.dtype),\n",
    "                                  stride=stride,\n",
    "                                  padding=padding)\n",
    "\n",
    "    # Coordinates of maxima residual to window center\n",
    "    # prepare kernel\n",
    "    coords_max: torch.Tensor = F.conv3d(x_exp,\n",
    "                                        window_kernel,\n",
    "                                        stride=stride,\n",
    "                                        padding=padding)\n",
    "\n",
    "    coords_max = coords_max / den.expand_as(coords_max)\n",
    "    coords_max = coords_max + grid_global_pooled.expand_as(coords_max)\n",
    "    # [:,:, 0, ...] is x\n",
    "    # [:,:, 1, ...] is y\n",
    "\n",
    "    if normalized_coordinates:\n",
    "        coords_max = normalize_pixel_coordinates3d(coords_max.permute(0, 2, 3, 4, 1), d, h, w)\n",
    "        coords_max = coords_max.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "    # Back B*C -> (b, c)\n",
    "    coords_max = coords_max.view(b, c, 3, coords_max.size(2), coords_max.size(3), coords_max.size(4))\n",
    "\n",
    "    if output_value:\n",
    "        return coords_max, x_softmaxpool\n",
    "    return coords_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 5, 5])\n",
      "torch.Size([2, 1, 1, 5, 5]) torch.Size([2, 1, 3, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print (inp2.shape)\n",
    "coord, resp = conv_soft_argmax3d(inp2, (1, 3,3), (1, 1,1), padding=(0,1,1),\n",
    "                                      normalized_coordinates=False,\n",
    "                                      temperature=torch.tensor(10.),\n",
    "                                      output_value=True)\n",
    "print(resp.shape, coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "          [[[ 0.5128,  1.0000,  1.9828,  3.0000,  3.5000],\n",
      "            [ 0.5086,  1.0000,  1.9884,  3.0000,  3.5000],\n",
      "            [ 0.5086,  1.0000,  2.0000,  3.0000,  3.4914],\n",
      "            [ 0.5000,  1.0000,  2.0116,  3.0000,  3.4914],\n",
      "            [ 0.5000,  1.0000,  2.0172,  3.0000,  3.4872]]],\n",
      "\n",
      "\n",
      "          [[[ 0.5128,  0.5086,  0.5086,  0.5000,  0.5000],\n",
      "            [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "            [ 1.9828,  1.9884,  2.0000,  2.0116,  2.0172],\n",
      "            [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000],\n",
      "            [ 3.5000,  3.5000,  3.4914,  3.4914,  3.4872]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "            [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "          [[[ 0.5000,  1.0000,  2.0172,  3.0000,  3.4872],\n",
      "            [ 0.5000,  1.0000,  2.0116,  3.0000,  3.4914],\n",
      "            [ 0.5086,  1.0000,  2.0000,  3.0000,  3.4914],\n",
      "            [ 0.5086,  1.0000,  1.9884,  3.0000,  3.5000],\n",
      "            [ 0.5128,  1.0000,  1.9828,  3.0000,  3.5000]]],\n",
      "\n",
      "\n",
      "          [[[ 0.5000,  0.5000,  0.5086,  0.5086,  0.5128],\n",
      "            [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "            [ 2.0172,  2.0116,  2.0000,  1.9884,  1.9828],\n",
      "            [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000],\n",
      "            [ 3.4872,  3.4914,  3.4914,  3.5000,  3.5000]]]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(kornia.utils.tensor_to_image(coord[0,0,0]))\n",
    "print (coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef conv_soft_argmax3d(input: torch.Tensor,\n",
    "                       kernel_size: Tuple[int, int, int] = (3, 3, 3),\n",
    "                       stride: Tuple[int, int, int] = (1, 1, 1),\n",
    "                       padding: Tuple[int, int, int] = (1, 1, 1),\n",
    "                       temperature: Union[torch.Tensor, float] = torch.tensor(1.0),\n",
    "                       normalized_coordinates: bool = True,\n",
    "                       eps: float = 1e-8,\n",
    "                       output_value: bool = False) -> Union[torch.Tensor,\n",
    "                                                            Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Function that computes the convolutional spatial Soft-Argmax 3D over the windows\n",
    "    of a given input heatmap. Function has two outputs: argmax coordinates and the softmaxpooled heatmap values\n",
    "    themselves.\n",
    "\n",
    "    On each window, the function computed is:\n",
    "\n",
    "    .. math::\n",
    "        ijk(X) = \\frac{\\sum_{(i,j,k) * exp(x / T)  \\in X}} {\\sum_{exp(x / T)  \\in X}}\n",
    "        val(X) = \\frac{\\sum_{x * exp(x / T)  \\in X}} {\\sum_{exp(x / T)  \\in X}}\n",
    "\n",
    "    - where T is temperature.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (Tuple([int,int,int])): the size of the window\n",
    "        stride  (Tuple([int,int,int])): the stride of the window.\n",
    "        padding (Tuple([int,int,int])): input zero padding\n",
    "        temperature (torch.Tensor): factor to apply to input. Default is 1.\n",
    "        normalized_coordinates (bool): whether to return the\n",
    "          coordinates normalized in the range of [-1, 1]. Otherwise,\n",
    "          it will return the coordinates in the range of the input shape.\n",
    "          Default is True.\n",
    "        eps (float): small value to avoid zero division. Default is 1e-8.\n",
    "        output_value(bool): if True, val is outputed, if False, only ij\n",
    "\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`\n",
    "        - Output: math:`(N, C, 3, D_{out}, H_{out}, W_{out})`, :math:`(N, C, D_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{D_{in}  + 2 \\times \\text{padding}[0] -\n",
    "              (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[1] -\n",
    "              (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[2] -\n",
    "              (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> input = torch.randn(20, 16, 3, 50, 32)\n",
    "        >>> nms_coords, nms_val = conv_soft_argmax2d(input, (3, 3, 3), (1, 2, 2), (0, 1, 1))\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(input):\n",
    "        raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                        .format(type(input)))\n",
    "    if not len(input.shape) == 5:\n",
    "        raise ValueError(\"Invalid input shape, we expect BxCxDxHxW. Got: {}\"\n",
    "                         .format(input.shape))\n",
    "    if temperature <= 0:\n",
    "        raise ValueError(\"Temperature should be positive float or tensor. Got: {}\"\n",
    "                         .format(temperature))\n",
    "\n",
    "    b, c, d, h, w = input.shape\n",
    "    input = input.view(b * c, d, h, w)\n",
    "\n",
    "    center_kernel = _get_center_kernel3d(kernel_size[0], kernel_size[1], kernel_size[2])\n",
    "    window_kernel = _get_window_grid_kernel3d(kernel_size[0], kernel_size[1], kernel_size[2])\n",
    "    window_kernel = window_kernel.to(input.device).to(input.dtype)\n",
    "\n",
    "    x_exp = (input / temperature).exp()\n",
    "\n",
    "    pool_coef: float = float(kernel_size[0] * kernel_size[1], kernel_size[2])\n",
    "\n",
    "    # softmax denominator\n",
    "    den = pool_coef * F.avg_pool3d(x_exp.view(input.size()),\n",
    "                                   kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding) + 1e-12\n",
    "\n",
    "    x_softmaxpool = pool_coef * F.avg_pool3d(x_exp.view(input.size()) * input,\n",
    "                                             kernel_size,\n",
    "                                             stride=stride,\n",
    "                                             padding=padding) / den\n",
    "    x_softmaxpool = x_softmaxpool.view(b,\n",
    "                                       c,\n",
    "                                       x_softmaxpool.size(2),\n",
    "                                       x_softmaxpool.size(3),\n",
    "                                       x_softmaxpool.size(4))\n",
    "\n",
    "    # We need to output also coordinates\n",
    "    # Pooled window center coordinates\n",
    "    grid_global: torch.Tensor = create_meshgrid(h, w, False).permute(0, 3, 1, 2)\n",
    "    grid_global = grid_global.to(input.device).to(input.dtype)\n",
    "    grid_global_pooled = F.conv2d(grid_global,\n",
    "                                  center_kernel.to(input.device).to(input.dtype),\n",
    "                                  stride=stride,\n",
    "                                  padding=padding)\n",
    "\n",
    "    # Coordinates of maxima residual to window center\n",
    "    # prepare kernel\n",
    "    coords_max: torch.Tensor = F.conv2d(x_exp,\n",
    "                                        window_kernel,\n",
    "                                        stride=stride,\n",
    "                                        padding=padding)\n",
    "\n",
    "    coords_max = coords_max / den.expand_as(coords_max)\n",
    "    coords_max = coords_max + grid_global_pooled.expand_as(coords_max)\n",
    "    # [:,:, 0, ...] is x\n",
    "    # [:,:, 1, ...] is y\n",
    "\n",
    "    if normalized_coordinates:\n",
    "        coords_max = normalize_pixel_coordinates(coords_max.permute(0, 2, 3, 1), h, w)\n",
    "        coords_max = coords_max.permute(0, 3, 1, 2)\n",
    "\n",
    "    # Back B*C -> (b, c)\n",
    "    coords_max = coords_max.view(b, c, 2, coords_max.size(2), coords_max.size(3))\n",
    "\n",
    "    if output_value:\n",
    "        return coords_max, x_softmaxpool\n",
    "    return coords_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1., 3.],\n",
      "           [1., 3.]],\n",
      "\n",
      "          [[1., 1.],\n",
      "           [3., 3.]]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(kornia.utils.tensor_to_image(coord[:,:,1]))\n",
    "\n",
    "print(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[0.0000, 0.9996, 0.9996, 0.0000],\n",
      "          [0.9996, 0.9998, 0.9998, 0.9996],\n",
      "          [0.9996, 0.9998, 0.9998, 0.9996]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
